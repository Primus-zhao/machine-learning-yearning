# 37. 如何决定是否使用所有数据
假设你的猫咪检测器的训练集包含1万张用户上传的图片。这些数据与独立的开发/测试集来自相同的分布，并代表你关心并想做好的分布。你还有额外的2万张从互联网下载的图片。你应该将所有的20000+10000=30000张图片提供给学习算法作为它的训练集吗？还是丢弃这2万张互联网图片，以免它会影响你的学习算法呢？

当使用早期的学习算法时（例如手工设计的计算机视觉特征，加上一个简单的线性分类器），合并两种类型的数据确实会造成算法表现糟糕的风险。因此，一些工程师会告诫你不要包含那2W万张互联网图片。

但有了现代强大灵活的学习算法（例如大型神经网络），以上这种风险被大大降低。如果你能构建一个拥有足够数量的隐藏单元/层的神经网络，你可以安全地将这2万张图片加入训练集中。添加这些图片更有可能提升你的表现。

该观察依赖于一个事实，就是有一些 x->y 的映射在两种类型的数据上都能很好的工作。换句话说，存在某个系统，不论你输入从互联网下载的图片还是移动app端的图片都能得到可靠的预测标签，即便不知道图片的来源。

添加额外的2万张图片有如下影响：

1. 它给你的神经网络提供更多的猫咪长啥样和不长啥样的样例。这很有帮助，因为从互联网下载的图片和用户上传的移动app端图片都共享一些相似之处。神经网络可以将从互联网下载的图片中获取到的知识应用到移动app端的图像上。
2. 它迫使神经网络花费一些容量来学习互联网图片特定的属性（例如高分辨率，不同画面结构图像的分布，等等）。如果这些特性和移动app端的图片大不相同，它将消耗掉神经网络的一些表征能力。因此从移动app端图片分布中识别数据的能力就会降低，这才是你真正关心的。理论上来说，这可能会损害到你算法的性能。

换一种不同的术语来描述第二个影响，我们可以求助于小说中的人物夏洛克·福尔摩斯，他解释道大脑就像一个阁楼；它只有有限的空间。他说，“每增加一个知识，你就会忘记以前知道的一些东西。”因此，最重要的是，不要让无用的事实把有用的真相排挤出去。” 

> 来自阿瑟·柯南·道尔的《血字的研究》 

幸运的是，如果你有足够的计算能力来构建一个足够大的神经网络，也就是一个足够大的阁楼，那么这就不是一个严重的问题了。你有足够的能力从互联网和移动app端的图像中学习，而不会存在两种类型的数据在容量上的竞争。也即是说，你的算法的“大脑”足够大，不必担心会耗尽阁楼的空间。 

但是，如果你没有足够大的神经网络（或另一个高度灵活的学习算法），那么你应该更加关注与开发集/测试集的分布相匹配的训练数据。

如果你认为有些数据没有任何帮助，出于计算原因，那么你应该将这些数据排除在外。例如，假设你的开发/测试集主要包含一些内容是人物、地点、地标、动物的偶然图片。同时假设里面有大量的历史文档扫描图片：

<p align="center">
    <img src="figs/document.jpg" height="90%" width="90%">
</p>

这些文件不包含任何类似猫咪的东西。它们看起来和开发/测试集的分布完全不同。没有必要将这些数据作为负样本，因为上述第一个影响带来的好处在这种情况下几乎忽略不计——你的神经网络几乎没有任何东西可以从这些数据中学习，使得它可以应用到开发/测试集中，加入它们将会浪费计算资源和神经网络的表征能力。 