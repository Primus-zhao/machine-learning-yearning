# 41. 辨别偏差、方差和数据不匹配误差
假设在猫咪检测任务中，人类可以达到近乎完美的性能（0%误差），因此最优错误率大约是 0%。假设你有：

- 训练集上1%的误差
- 训练开发集上5%的误差
- 开发集上5%的误差

这告诉你什么？这说明现在存在高方差。先前描述的减少方差的方法应该可以使你取得进展。

现在，假设你的算法达到了：

- 训练集上10%的误差

- 训练开发集上11%的误差

- 开发集上12%的误差

这告诉你在训练集上有高可避免偏差。即算法在训练集上做的很差。减少偏差的方法应该有所帮助。

上面的两个例子，算法只遭受有高可避免偏差或高方差。算法可能同时遭受高可避免偏差，高方差和数据不匹配中任何组合的影响。例如：

- 训练集上10%的误差
- 训练开发集上11%的误差
- 开发集上20%的误差

算法遭受高可避免偏差和数据不匹配。然而，并没有在训练集分布上遭受高方差。

通过将不同类型误差绘制为表上的条目，可能更容易理解它们之间如何相互联系：

<p align="center">
    <img src="figs/errors.jpg" height="90%" width="90%">
</p>

继续以猫咪图像检测器为例子，你可以看到在 x 轴上有两种不同数据分布。在 y 轴上，有三种误差类型：人类水平误差，在算法已经训练过样例上的误差，在算法没有训练过样例上的误差。我们可以用上一章节中已经确定的不同类型的误差来填充表格。

如果你愿意，你也可以填写表格中剩下的两个框：通过让人来标注移动端猫咪图片数据并测量他们的误差，将其填入右上角的框中（在移动端图片上的人类水平表现）。通过将移动端猫咪图片（分布B）中的一小部分放入训练集中，以使得神经网络也可以学习到它，将其填入下一个框中。然后在数据子集上测量学习模型的误差。填入这两条附加条目有时可以提供关于算法在两种不同分布（分布A和B）的数据上的工作的额外洞见。

通过理解哪种类型的误差算法遭受得最多，你将能更好地决定是否专注于减少偏差、减少方差还是减少数据不匹配。