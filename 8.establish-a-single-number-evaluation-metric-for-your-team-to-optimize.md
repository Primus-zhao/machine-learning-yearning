# 8. 为你的团队进行算法优化建立一个单一值估指标
分类准确率是 **单值评估指标（single-number evaluation metric）**的一个示例：你在开发集（或测试集）上运行分类器，然后得到一个单值：样本正确分类的比例，即 **准确率 (accuracy)**。根据这个指标，如果分类器A获得97%的准确率，而分类器B获得90%的准确率，那么我们认为分类器A更好。

相比之下，**查准率 (Precision)** 和 **查全率 (Recall)** 就不是一个单值评估指标：它给出了两个数值来评估分类器。多值评估指标使得算法的比较更加困难。假设你的算法表现如下： 

<p align="center">
    <img src="figs/PR.jpg" height="80%" width="80%">
</p>

> 猫咪分类器的查准率是指在开发集（或测试集）中检测出的所有猫咪图片中有多少比例是真正的有猫。它的查全率（Recall）指在开发集（或测试集）中所有真正有猫咪的图片有多少比例被检测出来了。在高查准率和高查全率之间通常需要一个权衡。

可见两个分类器都没有显而易见的优势，所以它不能立即引导你选择其中一个。

在开发期间，你的团队会尝试大量关于算法架构、模型参数、特征选择等方面的想法。使用单值评估指标（如精确度）使得你可以根据其在该指标上的表现快速对所有模型进行排序，从而快速决定哪一个是能工作得最好的。

如果你真的既关心查准率又关心查全率，我推荐使用一种标准的方法将它们合并为单值指标。例如，可以取二者的平均值来表示一个单值指标。或者，你可以计算 **“F1度量 (F1 score)”**，这是一种基于其平均值改善的方法，比简单地取平均值效果要好。

> 如果你想要了解更多关于F1度量 (F1 score) 的内容，请参阅[https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score) 。它是基于查准率和查全率的调和平均定义的，其计算公式为2/((1/Precision)+(1/Recall))

<p align="center">
    <img src="figs/F1.jpg" height="80%" width="80%">
</p>

当你在大量的分类器中进行选择时，使用单值评估指标可以加快你做出决策。它给出了明确的性能排名，从而给出一个清晰的前进方向。

最后一个例子：假如你分别跟进四个主要市场 (美国，中国，印度和其他地区) 中猫咪分类器的准确率，将会得到四个指标。通过对这四个指标进行平均或加权平均，最终得到一个单值指标。取平均或加权平均是将多个指标融合为一个的最常见的方法之一。



