# 24. 偏差与方差的权衡
你可能听过“偏差和方差的权衡”。你能够对大部分学习算法进行的更改中，有一些能够减少偏差错误，但是是以增加方差为代价的，反之亦然。这就在偏差和方差之间产生了“权衡”。

例如，增加模型的大小（在神经网络中增加神经元/层，或增加输入特征），通常可以减少偏差，但可能会增加方差。另外，加入正则化一般会增加偏差，但是能减少方差。

当下，我们往往能够获取充足的数据，并且可以使用非常大的神经网络（深度学习）。因此，这种权衡减弱了，并且现在有更多的选择可以在不损害方差的情况下减少偏差，反之亦然。

例如，你通常可以增加神经网络的大小，并调整正则化方法去减少偏差，并且不明显地增加方差。通过增加训练数据，你通常也可以在不影响偏差的情况下减少方差。

如果你选择了一个很适合你任务的模型架构，那么你也可以同时减少偏差和方差。但选择到这样的架构是困难的。

在接下来的几个章节中，我们将讨论处理偏差和方差的额外特定技巧。